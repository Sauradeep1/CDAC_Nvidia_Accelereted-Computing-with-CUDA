{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract with NVTabular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this set of labs, we'll learn how to use [NVTabular](https://nvidia-merlin.github.io/NVTabular/main/Introduction.html) to create an ETL pipeline. The first step to any ETL pipeline is to `Extract` data from an already existing database. We will be using NOAA's [Climate Data Online (CDO) Dataset](https://www.ncdc.noaa.gov/cdo-web/datasets#LCD). Specifically, we will be using the [U.S. Local Climatological Data (LCD)](https://www.ncei.noaa.gov/metadata/geoportal/rest/metadata/item/gov.noaa.ncdc:C00684/html) which stores hourly climatological data for almost 2500 stations. It tracks temperature, dew point, precipitation and wind speeds among other things. A full description of the schema can be found in [this document](https://www1.ncdc.noaa.gov/pub/data/cdo/documentation/LCD_documentation.pdf).\n",
    "\n",
    "Our goal is to:\n",
    "1. Extract wind data from the LCD database\n",
    "2. Transform it to better understand the direction in which the wind blows\n",
    "3. Load it into a new file so others can use it for analysis\n",
    "\n",
    "<b>Learning Objectives</b>:\n",
    "* Learn how to use NVTabular to read multiple files at once\n",
    "* Learn how to visualize NVTabular's system of operations with a graph\n",
    "* Learn how to export data to a new file type for analysis\n",
    "* Learn how to monitor GPU resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Monitoring\n",
    "\n",
    "Before we get started with NVTabular and transforming data, it would be useful to see how these data pipelines impact our hardware. For this lab, we have multiple GPUs available, and we would like to use each one of them to its fullest ability.\n",
    "\n",
    "We are going to use the `nvidia-smi` command line tool to monitor our GPUs. Try running it below. We can also add a `-h` flag (commented out below) to see the full documentation of the command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 12 07:23:29 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            On   | 00000000:00:1B.0 Off |                    0 |\n",
      "| N/A   24C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla T4            On   | 00000000:00:1C.0 Off |                    0 |\n",
      "| N/A   22C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla T4            On   | 00000000:00:1D.0 Off |                    0 |\n",
      "| N/A   24C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   24C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi #-h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This displays useful information about our GPUs including:\n",
    "* `GPU`: The ID number of the GPU.\n",
    "* `Memory-Usage`: How much memory is on the GPU and how much if it has been used.\n",
    "* `GPU-Util`: The percent utilization of the GPU over the last second.\n",
    "\n",
    "Since there is only so much space our computer screens, let's customize our view of this tool. We can do so with the `--query-gpu` flag. We can pass it the specific properties we are interested in. Let's start with the following to monitor our GPU memory and utilization:\n",
    "\n",
    "* `index`: Zero based index of the GPU. Can change at each boot.\n",
    "* `memory.used`: Total memory allocated by active contexts.\n",
    "* `memory.total`: Total installed GPU memory.\n",
    "* `utilization.gpu`: Percent of time over the past sample period during which one or more kernels was executing on the GPU. The sample period may be between 1 second and 1/6 second depending on the product.\n",
    "\n",
    "When querying, we must also specify a `--format`. Let's use `csv` in order to make the output human readable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index, name, memory.used [MiB], memory.total [MiB], utilization.gpu [%]\n",
      "0, Tesla T4, 0 MiB, 15109 MiB, 0 %\n",
      "1, Tesla T4, 0 MiB, 15109 MiB, 0 %\n",
      "2, Tesla T4, 0 MiB, 15109 MiB, 0 %\n",
      "3, Tesla T4, 0 MiB, 15109 MiB, 0 %\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi --query-gpu=index,name,memory.used,memory.total,utilization.gpu --format=csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many more properties we can query. The following may also be of interest:\n",
    "\n",
    "* `name`: The official product name of the GPU.\n",
    "* `power.draw`: The last measured power draw for the entire board, in watts. Only available if power management is supported. This reading is accurate to within +/- 5 watts.\n",
    "* `temperature.gpu`: Core GPU temperature. in degrees C.\n",
    "A full list of properties can be found by running:\n",
    "`nvidia-smi --help-query-gpu`\n",
    "\n",
    "**TODO**: We can set this query to run periodically so we can see how our code impacts our GPU almost immediately. First, we should make a new terminal window. Create one by going to `File` > `New` > `Terminal`. This should create a new tab named `Terminal X` with `X` being the a number. Click and hold the tab name to move the tab around and place it where convenient, such as to the left or right edge or along the bottom. We recommend having both the notebook and the terminal visible on the screen.\n",
    "\n",
    "Next, we will use the [watch](https://linux.die.net/man/1/watch) command line tool in order to continually run `nvidia-smi`. The `-n` flag specifies the number of seconds to wait between repeating a command.\n",
    "\n",
    "Copy the following command into the new terminal window and run it by pressing the `ENTER` key. Feel free to modify which properties to query with the ones you are most interested in.\n",
    "\n",
    "`watch -n0.1 nvidia-smi --query-gpu=index,memory.used,memory.total,utilization.gpu --format=csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started with NVTabular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our hardware monitoring set up, let's begin building our NVTabular data pipeline based on NOAA's Local Climatological Data.\n",
    "\n",
    "We have already pulled the data for three stations and have stored them in the `data` folder. They are large files, so we do not recommend opening them in a Jupyter window. If you are interested in learning how to do this yourself, data can be ordered from the NOAA website using [this form](https://www.ncdc.noaa.gov/cdo-web/datatools/lcd). Up to ten years of data can be requested at a time, and email address is required for them to send the data to.\n",
    "\n",
    "Let's load one of these files into cuDF in order to understand it better. (Keep an eye on your terminal as this is running to watch the GPU memory usage climb higher.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>STATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>REPORT_TYPE</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>AWND</th>\n",
       "      <th>BackupDirection</th>\n",
       "      <th>BackupDistance</th>\n",
       "      <th>BackupDistanceUnit</th>\n",
       "      <th>BackupElements</th>\n",
       "      <th>...</th>\n",
       "      <th>ShortDurationPrecipitationValue060</th>\n",
       "      <th>ShortDurationPrecipitationValue080</th>\n",
       "      <th>ShortDurationPrecipitationValue100</th>\n",
       "      <th>ShortDurationPrecipitationValue120</th>\n",
       "      <th>ShortDurationPrecipitationValue150</th>\n",
       "      <th>ShortDurationPrecipitationValue180</th>\n",
       "      <th>Sunrise</th>\n",
       "      <th>Sunset</th>\n",
       "      <th>TStorms</th>\n",
       "      <th>WindEquipmentChangeDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>72058700184</td>\n",
       "      <td>2011-05-01T00:00:00</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>72058700184</td>\n",
       "      <td>2011-05-01T00:15:00</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>72058700184</td>\n",
       "      <td>2011-05-01T00:35:00</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>72058700184</td>\n",
       "      <td>2011-05-01T01:00:00</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>72058700184</td>\n",
       "      <td>2011-05-01T01:15:00</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      STATION                 DATE REPORT_TYPE SOURCE  AWND  \\\n",
       "0           0  72058700184  2011-05-01T00:00:00       FM-15      4  <NA>   \n",
       "1           1  72058700184  2011-05-01T00:15:00       AUTO       4  <NA>   \n",
       "2           2  72058700184  2011-05-01T00:35:00       AUTO       4  <NA>   \n",
       "3           3  72058700184  2011-05-01T01:00:00       FM-15      4  <NA>   \n",
       "4           4  72058700184  2011-05-01T01:15:00       AUTO       4  <NA>   \n",
       "\n",
       "  BackupDirection BackupDistance BackupDistanceUnit BackupElements  ...  \\\n",
       "0            <NA>           <NA>               <NA>           <NA>  ...   \n",
       "1            <NA>           <NA>               <NA>           <NA>  ...   \n",
       "2            <NA>           <NA>               <NA>           <NA>  ...   \n",
       "3            <NA>           <NA>               <NA>           <NA>  ...   \n",
       "4            <NA>           <NA>               <NA>           <NA>  ...   \n",
       "\n",
       "  ShortDurationPrecipitationValue060 ShortDurationPrecipitationValue080  \\\n",
       "0                               <NA>                               <NA>   \n",
       "1                               <NA>                               <NA>   \n",
       "2                               <NA>                               <NA>   \n",
       "3                               <NA>                               <NA>   \n",
       "4                               <NA>                               <NA>   \n",
       "\n",
       "  ShortDurationPrecipitationValue100 ShortDurationPrecipitationValue120  \\\n",
       "0                               <NA>                               <NA>   \n",
       "1                               <NA>                               <NA>   \n",
       "2                               <NA>                               <NA>   \n",
       "3                               <NA>                               <NA>   \n",
       "4                               <NA>                               <NA>   \n",
       "\n",
       "  ShortDurationPrecipitationValue150 ShortDurationPrecipitationValue180  \\\n",
       "0                               <NA>                               <NA>   \n",
       "1                               <NA>                               <NA>   \n",
       "2                               <NA>                               <NA>   \n",
       "3                               <NA>                               <NA>   \n",
       "4                               <NA>                               <NA>   \n",
       "\n",
       "  Sunrise Sunset TStorms WindEquipmentChangeDate  \n",
       "0    <NA>   <NA>    <NA>                    <NA>  \n",
       "1    <NA>   <NA>    <NA>                    <NA>  \n",
       "2    <NA>   <NA>    <NA>                    <NA>  \n",
       "3    <NA>   <NA>    <NA>                    <NA>  \n",
       "4    <NA>   <NA>    <NA>                    <NA>  \n",
       "\n",
       "[5 rows x 125 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cudf\n",
    "df = cudf.read_csv(\"data/2563867.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is **sparse**, meaning that most of the values are empty. Here, this empty data is displayed as `<NA>`. Let's look at the first few rows at the raw data to see what is happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",STATION,DATE,REPORT_TYPE,SOURCE,AWND,BackupDirection,BackupDistance,BackupDistanceUnit,BackupElements,BackupElevation,BackupElevationUnit,BackupEquipment,BackupLatitude,BackupLongitude,BackupName,CDSD,CLDD,DSNW,DailyAverageDewPointTemperature,DailyAverageDryBulbTemperature,DailyAverageRelativeHumidity,DailyAverageSeaLevelPressure,DailyAverageStationPressure,DailyAverageWetBulbTemperature,DailyAverageWindSpeed,DailyCoolingDegreeDays,DailyDepartureFromNormalAverageTemperature,DailyHeatingDegreeDays,DailyMaximumDryBulbTemperature,DailyMinimumDryBulbTemperature,DailyPeakWindDirection,DailyPeakWindSpeed,DailyPrecipitation,DailySnowDepth,DailySnowfall,DailySustainedWindDirection,DailySustainedWindSpeed,DailyWeather,HDSD,HTDD,HeavyFog,HourlyAltimeterSetting,HourlyDewPointTemperature,HourlyDryBulbTemperature,HourlyPrecipitation,HourlyPresentWeatherType,HourlyPressureChange,HourlyPressureTendency,HourlyRelativeHumidity,HourlySeaLevelPressure,HourlySkyConditions,HourlyStationPressure,HourlyVisibility,HourlyWetBulbTemperature,HourlyWindDirection,HourlyWindGustSpeed,HourlyWindSpeed,MonthlyAverageRH,MonthlyDaysWithGT001Precip,MonthlyDaysWithGT010Precip,MonthlyDaysWithGT32Temp,MonthlyDaysWithGT90Temp,MonthlyDaysWithLT0Temp,MonthlyDaysWithLT32Temp,MonthlyDepartureFromNormalAverageTemperature,MonthlyDepartureFromNormalCoolingDegreeDays,MonthlyDepartureFromNormalHeatingDegreeDays,MonthlyDepartureFromNormalMaximumTemperature,MonthlyDepartureFromNormalMinimumTemperature,MonthlyDepartureFromNormalPrecipitation,MonthlyDewpointTemperature,MonthlyGreatestPrecip,MonthlyGreatestPrecipDate,MonthlyGreatestSnowDepth,MonthlyGreatestSnowDepthDate,MonthlyGreatestSnowfall,MonthlyGreatestSnowfallDate,MonthlyMaxSeaLevelPressureValue,MonthlyMaxSeaLevelPressureValueDate,MonthlyMaxSeaLevelPressureValueTime,MonthlyMaximumTemperature,MonthlyMeanTemperature,MonthlyMinSeaLevelPressureValue,MonthlyMinSeaLevelPressureValueDate,MonthlyMinSeaLevelPressureValueTime,MonthlyMinimumTemperature,MonthlySeaLevelPressure,MonthlyStationPressure,MonthlyTotalLiquidPrecipitation,MonthlyTotalSnowfall,MonthlyWetBulb,NormalsCoolingDegreeDay,NormalsHeatingDegreeDay,REM,REPORT_TYPE.1,SOURCE.1,ShortDurationEndDate005,ShortDurationEndDate010,ShortDurationEndDate015,ShortDurationEndDate020,ShortDurationEndDate030,ShortDurationEndDate045,ShortDurationEndDate060,ShortDurationEndDate080,ShortDurationEndDate100,ShortDurationEndDate120,ShortDurationEndDate150,ShortDurationEndDate180,ShortDurationPrecipitationValue005,ShortDurationPrecipitationValue010,ShortDurationPrecipitationValue015,ShortDurationPrecipitationValue020,ShortDurationPrecipitationValue030,ShortDurationPrecipitationValue045,ShortDurationPrecipitationValue060,ShortDurationPrecipitationValue080,ShortDurationPrecipitationValue100,ShortDurationPrecipitationValue120,ShortDurationPrecipitationValue150,ShortDurationPrecipitationValue180,Sunrise,Sunset,TStorms,WindEquipmentChangeDate\n",
      "0,72058700184,2011-05-01T00:00:00,FM-15,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,29.92,72.0,75.0,,,,,89.0,,,,10.0,,130.0,,9.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,MET064METAR K0R3 010555Z AUTO 13008KT 10SM OVC017 24/22 A2992 RMK AO2;,FM-15,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "1,72058700184,2011-05-01T00:15:00,AUTO ,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,29.92,72.0,75.0,,,,,89.0,,,,10.0,,120.0,,9.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,MET064METAR K0R3 010615Z AUTO 12008KT 10SM OVC016 24/22 A2992 RMK AO2;,AUTO ,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "2,72058700184,2011-05-01T00:35:00,AUTO ,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,29.91,72.0,75.0,,,,,89.0,,,,10.0,,120.0,18.0,11.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,MET067METAR K0R3 010635Z AUTO 12010G16KT 10SM OVC014 24/22 A2991 RMK AO2;,AUTO ,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "3,72058700184,2011-05-01T01:00:00,FM-15,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,29.90,72.0,75.0,,,,,89.0,,BKN:07 14 OVC:08 18,,10.0,,130.0,19.0,14.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,MET074METAR K0R3 010655Z AUTO 13012G17KT 10SM BKN014 OVC018 24/22 A2990 RMK AO2;,FM-15,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "4,72058700184,2011-05-01T01:15:00,AUTO ,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,29.90,72.0,75.0,,,,,89.0,,,,10.0,,130.0,,13.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,MET064METAR K0R3 010715Z AUTO 13011KT 10SM OVC012 24/22 A2990 RMK AO2;,AUTO ,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "5,72058700184,2011-05-01T01:35:00,AUTO ,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,29.90,72.0,75.0,,,,,89.0,,,,10.0,,130.0,16.0,10.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,MET067METAR K0R3 010735Z AUTO 13009G14KT 10SM OVC012 24/22 A2990 RMK AO2;,AUTO ,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "6,72058700184,2011-05-01T02:00:00,FM-15,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,29.89,72.0,75.0,,,,,89.0,,,,10.0,,130.0,17.0,11.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,MET067METAR K0R3 010755Z AUTO 13010G15KT 10SM OVC010 24/22 A2989 RMK AO2;,FM-15,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "7,72058700184,2011-05-01T02:15:00,AUTO ,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,29.89,72.0,75.0,,,,,89.0,,,,10.0,,130.0,,10.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,MET064METAR K0R3 010815Z AUTO 13009KT 10SM OVC010 24/22 A2989 RMK AO2;,AUTO ,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "8,72058700184,2011-05-01T02:35:00,AUTO ,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,29.89,72.0,75.0,,,,,89.0,,,,10.0,,130.0,,13.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,MET064METAR K0R3 010835Z AUTO 13011KT 10SM OVC010 24/22 A2989 RMK AO2;,AUTO ,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n"
     ]
    }
   ],
   "source": [
    "!head data/2563867.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the long strings of commas? Those are many cells in a row without any data. The CSV file format does not offer much compression, so the first ETL pipeline we will make is to convert our CSV files in an [Apache Parquet](https://parquet.apache.org/) file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NVTabular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[NVTabular](https://nvidia-merlin.github.io/NVTabular/main/Introduction.html#nvtabular-api-documentation)** is a library for fast tabular data transformation and loading, manipulating terabyte-scale datasets quickly. It provides best practices for feature engineering and preprocessing and a high-level abstraction to simplify code accelerating computation on the GPU using the RAPIDS cuDF library. It was originally created for Recommender System data pipelines, but it is not limited in this scope.\n",
    "\n",
    "<center><img src='https://developer.nvidia.com/blog/wp-content/uploads/2020/07/recommender-system-training-pipeline-1.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NVTabular has 4 main components**:\n",
    "* <b>1. Dataset</b>: A [dataset](https://nvidia-merlin.github.io/NVTabular/main/api/dataset.html#) contains a list of files and iterates over the files. If necessary, it will read a file in chunks.\n",
    "* <b>2. Op</b>: An [Op](https://nvidia-merlin.github.io/NVTabular/main/api/ops/index.html) defines a calculation. For example, an op could be to collect the mean/std for a column, filling missing values or combine two categories.\n",
    "* <b>3. Workflow</b>: A [workflow](https://nvidia-merlin.github.io/NVTabular/main/api/workflow/workflow.html) orchestrates the pipeline. We will take a more detailed look on that in the following notebooks.\n",
    "* <b>4. Dataloader</b>: NVTabular provides optimized dataloader for tabular data in [PyTorch](https://nvidia-merlin.github.io/NVTabular/main/api/torch_dataloader.html) and [TensorFlow](https://nvidia-merlin.github.io/NVTabular/main/api/tensorflow_dataloader.html). This is primarily used for machine learning.\n",
    "\n",
    "For our weather dataset, many of the columns in our raw dataset are empty, so let's define an NVTabular workflow. The steps are to:\n",
    "1. Define a [ColumnGroup](https://nvidia-merlin.github.io/NVTabular/main/resources/architecture.html?highlight=columngroup)\n",
    "2. Initialize the NVTabular workflow\n",
    "3. Initialize the NVTabular dataset\n",
    "4. Transform the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nvtabular as nvt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1. Define a ColumnGroup</b>\n",
    "\n",
    "As we define our pipeline, we will begin at the source. NVTabular reads the column names in our source files in order to locate data, so let's take a look at which columns have data in order to decide what to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                      250676\n",
       "STATION                                         250676\n",
       "DATE                                            250676\n",
       "REPORT_TYPE                                     250676\n",
       "SOURCE                                          250676\n",
       "AWND                                                 0\n",
       "BackupDirection                                      0\n",
       "BackupDistance                                       0\n",
       "BackupDistanceUnit                                   0\n",
       "BackupElements                                       0\n",
       "BackupElevation                                      0\n",
       "BackupElevationUnit                                  0\n",
       "BackupEquipment                                      0\n",
       "BackupLatitude                                       0\n",
       "BackupLongitude                                      0\n",
       "BackupName                                           0\n",
       "CDSD                                                 0\n",
       "CLDD                                                 0\n",
       "DSNW                                                 0\n",
       "DailyAverageDewPointTemperature                      0\n",
       "DailyAverageDryBulbTemperature                       0\n",
       "DailyAverageRelativeHumidity                         0\n",
       "DailyAverageSeaLevelPressure                         0\n",
       "DailyAverageStationPressure                          0\n",
       "DailyAverageWetBulbTemperature                       0\n",
       "DailyAverageWindSpeed                                0\n",
       "DailyCoolingDegreeDays                               0\n",
       "DailyDepartureFromNormalAverageTemperature           0\n",
       "DailyHeatingDegreeDays                               0\n",
       "DailyMaximumDryBulbTemperature                       0\n",
       "DailyMinimumDryBulbTemperature                       0\n",
       "DailyPeakWindDirection                               0\n",
       "DailyPeakWindSpeed                                   0\n",
       "DailyPrecipitation                                   0\n",
       "DailySnowDepth                                       0\n",
       "DailySnowfall                                        0\n",
       "DailySustainedWindDirection                          0\n",
       "DailySustainedWindSpeed                              0\n",
       "DailyWeather                                      2541\n",
       "HDSD                                                 0\n",
       "HTDD                                                 0\n",
       "HeavyFog                                             0\n",
       "HourlyAltimeterSetting                          248107\n",
       "HourlyDewPointTemperature                       241649\n",
       "HourlyDryBulbTemperature                        241731\n",
       "HourlyPrecipitation                               9286\n",
       "HourlyPresentWeatherType                         30823\n",
       "HourlyPressureChange                                 0\n",
       "HourlyPressureTendency                               0\n",
       "HourlyRelativeHumidity                          241649\n",
       "HourlySeaLevelPressure                               0\n",
       "HourlySkyConditions                             177796\n",
       "HourlyStationPressure                           161683\n",
       "HourlyVisibility                                238506\n",
       "HourlyWetBulbTemperature                        161216\n",
       "HourlyWindDirection                             242329\n",
       "HourlyWindGustSpeed                              33837\n",
       "HourlyWindSpeed                                 243267\n",
       "MonthlyAverageRH                                     0\n",
       "MonthlyDaysWithGT001Precip                           0\n",
       "MonthlyDaysWithGT010Precip                           0\n",
       "MonthlyDaysWithGT32Temp                              0\n",
       "MonthlyDaysWithGT90Temp                              0\n",
       "MonthlyDaysWithLT0Temp                               0\n",
       "MonthlyDaysWithLT32Temp                              0\n",
       "MonthlyDepartureFromNormalAverageTemperature         0\n",
       "MonthlyDepartureFromNormalCoolingDegreeDays          0\n",
       "MonthlyDepartureFromNormalHeatingDegreeDays          0\n",
       "MonthlyDepartureFromNormalMaximumTemperature         0\n",
       "MonthlyDepartureFromNormalMinimumTemperature         0\n",
       "MonthlyDepartureFromNormalPrecipitation              0\n",
       "MonthlyDewpointTemperature                           0\n",
       "MonthlyGreatestPrecip                                0\n",
       "MonthlyGreatestPrecipDate                            0\n",
       "MonthlyGreatestSnowDepth                             0\n",
       "MonthlyGreatestSnowDepthDate                         0\n",
       "MonthlyGreatestSnowfall                              0\n",
       "MonthlyGreatestSnowfallDate                          0\n",
       "MonthlyMaxSeaLevelPressureValue                      0\n",
       "MonthlyMaxSeaLevelPressureValueDate                  0\n",
       "MonthlyMaxSeaLevelPressureValueTime                  0\n",
       "MonthlyMaximumTemperature                            0\n",
       "MonthlyMeanTemperature                               0\n",
       "MonthlyMinSeaLevelPressureValue                      0\n",
       "MonthlyMinSeaLevelPressureValueDate                  0\n",
       "MonthlyMinSeaLevelPressureValueTime                  0\n",
       "MonthlyMinimumTemperature                            0\n",
       "MonthlySeaLevelPressure                              0\n",
       "MonthlyStationPressure                               0\n",
       "MonthlyTotalLiquidPrecipitation                      0\n",
       "MonthlyTotalSnowfall                                 0\n",
       "MonthlyWetBulb                                       0\n",
       "NormalsCoolingDegreeDay                              0\n",
       "NormalsHeatingDegreeDay                              0\n",
       "REM                                             248135\n",
       "REPORT_TYPE.1                                   250676\n",
       "SOURCE.1                                        250676\n",
       "ShortDurationEndDate005                              0\n",
       "ShortDurationEndDate010                              0\n",
       "ShortDurationEndDate015                              0\n",
       "ShortDurationEndDate020                              0\n",
       "ShortDurationEndDate030                              0\n",
       "ShortDurationEndDate045                              0\n",
       "ShortDurationEndDate060                              0\n",
       "ShortDurationEndDate080                              0\n",
       "ShortDurationEndDate100                              0\n",
       "ShortDurationEndDate120                              0\n",
       "ShortDurationEndDate150                              0\n",
       "ShortDurationEndDate180                              0\n",
       "ShortDurationPrecipitationValue005                   0\n",
       "ShortDurationPrecipitationValue010                   0\n",
       "ShortDurationPrecipitationValue015                   0\n",
       "ShortDurationPrecipitationValue020                   0\n",
       "ShortDurationPrecipitationValue030                   0\n",
       "ShortDurationPrecipitationValue045                   0\n",
       "ShortDurationPrecipitationValue060                   0\n",
       "ShortDurationPrecipitationValue080                   0\n",
       "ShortDurationPrecipitationValue100                   0\n",
       "ShortDurationPrecipitationValue120                   0\n",
       "ShortDurationPrecipitationValue150                   0\n",
       "ShortDurationPrecipitationValue180                   0\n",
       "Sunrise                                           2541\n",
       "Sunset                                            2541\n",
       "TStorms                                              0\n",
       "WindEquipmentChangeDate                              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 200\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most of the daily, monthly, and short duration data is missing, but there is a good amount of hourly data. Let's extract these hourly columns to explore them further.\n",
    "\n",
    "To do this, we will pass NVTabular a list of column names to create a [ColumnGroup](https://nvidia-merlin.github.io/NVTabular/main/resources/architecture.html?highlight=columngroup). In the next notebook, we will learn how to transform these columns with Ops, but for now, we will use the ColumnGroup to simply filter our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"STATION\",\n",
    "    \"DATE\",\n",
    "    \"HourlyDewPointTemperature\",\n",
    "    \"HourlyDryBulbTemperature\",\n",
    "    \"HourlyPrecipitation\",\n",
    "    \"HourlyRelativeHumidity\",\n",
    "    \"HourlyWetBulbTemperature\",\n",
    "    \"HourlyWindDirection\",\n",
    "    \"HourlyWindSpeed\",\n",
    "]\n",
    "column_group = nvt.ColumnGroup(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2. Initialize the NVTabular workflow</b>\n",
    "\n",
    "Next, we can initialize an NVTabular [workflow](https://nvidia-merlin.github.io/NVTabular/main/api/workflow/workflow.html) with our pipeline. This defines the system of operations to be done on our columns. To do this, it constructs a DAG with [Dask](https://dask.org/) that is visible by calling `.column_group.graph` on the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"620pt\" height=\"116pt\"\n",
       " viewBox=\"0.00 0.00 620.25 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-112 616.2457,-112 616.2457,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"306.1228\" cy=\"-90\" rx=\"299.7469\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"306.1228\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">input cols=[STATION, DATE, HourlyDewPointTemperature...]</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"306.1228\" cy=\"-18\" rx=\"306.2457\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"306.1228\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">output cols=[STATION, DATE, HourlyDewPointTemperature...]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M306.1228,-71.8314C306.1228,-64.131 306.1228,-54.9743 306.1228,-46.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"309.6229,-46.4132 306.1228,-36.4133 302.6229,-46.4133 309.6229,-46.4132\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f1110f587d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = nvt.Workflow(column_group)\n",
    "workflow.column_group.graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we are not transforming any data, so our graph only has two steps:\n",
    "1. Extract the defined input columns\n",
    "2. Output those defined input columns\n",
    "\n",
    "<b>3. Initialize the NVTabular dataset</b>\n",
    "\n",
    "NVTabular [Dataset](https://nvidia-merlin.github.io/NVTabular/main/api/dataset.html#) is a universal wrapper for datasets. The main purpose is to abstract away the raw format of the dataset and allow NVTabular to rely on a universal format. In addition, NVTabular Dataset partitions the data and if necessary reads the file in chunks to avoid exceeding the GPU memory.<br><br>\n",
    "NVTabular [Dataset](https://nvidia-merlin.github.io/NVTabular/main/api/dataset.html#) supports multiple input formats, such as:\n",
    "* reading data in format `.avro`, `.parquet` or `.csv` \n",
    "* reading data from different file storages: `local disk`, `AWS S3` or `Google Cloud Storage` \n",
    "* directly `cudf.DataFrame` or `dask_cudf.DataFrame`\n",
    "\n",
    "If we want to pass in multiple files at once, we can do so with a list of file paths. Thankfully, the python [glob](https://docs.python.org/3/library/glob.html) module can give us exactly that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/2565221.csv', 'data/2563867.csv', 'data/2565262.csv']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "file_paths = glob.glob(\"data/*.csv\")\n",
    "file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = nvt.Dataset(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nvtabular.io.dataset.Dataset at 0x7f1228528b90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>4. Transform the dataset</b>\n",
    "\n",
    "Now that we have defined our workflow and data sources, we can run our pipeline to *load* our data into a new output destination.\n",
    "\n",
    "We'll start by running our `dataset` through our simple workflow DAG with [transform](https://nvidia-merlin.github.io/NVTabular/main/api/workflow/workflow.html#nvtabular.workflow.workflow.Workflow.transform). Then, we will export it with [to_parquet](https://nvidia-merlin.github.io/NVTabular/main/api/dataset.html#nvtabular.io.dataset.Dataset.to_parquet).\n",
    "\n",
    "*Note*: If we have already ran this pipeline before, we can clear out the previous result with the below code to make way for the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf data/parquet_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have been setting up the pipeline, we have not been using our GPU resources. Watch that change as the below pipeline runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.transform(dataset).to_parquet(output_path=\"data/parquet_out/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the new `data/parquet_out` folder. The entire directory is much smaller than any one of our CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root  73M Feb 12 07:13 data/2563867.csv\n",
      "-rw-r--r-- 1 root root  64M Feb 12 07:13 data/2565221.csv\n",
      "-rw-r--r-- 1 root root  34M Feb 12 07:13 data/2565262.csv\n",
      "\n",
      "data/parquet_out:\n",
      "total 14M\n",
      "-rw-r--r-- 1 root root  14M Feb 12 07:26 0.39e087bc67604a55ad924b2dac9fc2c6.parquet\n",
      "-rw-r--r-- 1 root root   62 Feb 12 07:26 _file_list.txt\n",
      "-rw-r--r-- 1 root root 5.1K Feb 12 07:26 _metadata\n",
      "-rw-r--r-- 1 root root  136 Feb 12 07:26 _metadata.json\n"
     ]
    }
   ],
   "source": [
    "!ls data/* -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review the output\n",
    "\n",
    "Even though our pipeline ran, it does not mean the data was exported correctly. Let's take a look on our processed data to verify that is as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>HourlyDewPointTemperature</th>\n",
       "      <th>HourlyDryBulbTemperature</th>\n",
       "      <th>HourlyPrecipitation</th>\n",
       "      <th>HourlyRelativeHumidity</th>\n",
       "      <th>HourlyWetBulbTemperature</th>\n",
       "      <th>HourlyWindDirection</th>\n",
       "      <th>HourlyWindSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72058700184</td>\n",
       "      <td>2011-05-01T00:00:00</td>\n",
       "      <td>72.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>89.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>130.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72058700184</td>\n",
       "      <td>2011-05-01T00:15:00</td>\n",
       "      <td>72.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>89.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>120.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72058700184</td>\n",
       "      <td>2011-05-01T00:35:00</td>\n",
       "      <td>72.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>89.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>120.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72058700184</td>\n",
       "      <td>2011-05-01T01:00:00</td>\n",
       "      <td>72.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>89.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>130.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72058700184</td>\n",
       "      <td>2011-05-01T01:15:00</td>\n",
       "      <td>72.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>89.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>130.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>72058700184</td>\n",
       "      <td>2011-05-01T01:35:00</td>\n",
       "      <td>72.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>89.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>130.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>72058700184</td>\n",
       "      <td>2011-05-01T02:00:00</td>\n",
       "      <td>72.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>89.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>130.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>72058700184</td>\n",
       "      <td>2011-05-01T02:15:00</td>\n",
       "      <td>72.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>89.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>130.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>72058700184</td>\n",
       "      <td>2011-05-01T02:35:00</td>\n",
       "      <td>72.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>89.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>130.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>72058700184</td>\n",
       "      <td>2011-05-01T03:00:00</td>\n",
       "      <td>73.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>94.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>130.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATION                 DATE  HourlyDewPointTemperature  \\\n",
       "0  72058700184  2011-05-01T00:00:00                       72.0   \n",
       "1  72058700184  2011-05-01T00:15:00                       72.0   \n",
       "2  72058700184  2011-05-01T00:35:00                       72.0   \n",
       "3  72058700184  2011-05-01T01:00:00                       72.0   \n",
       "4  72058700184  2011-05-01T01:15:00                       72.0   \n",
       "5  72058700184  2011-05-01T01:35:00                       72.0   \n",
       "6  72058700184  2011-05-01T02:00:00                       72.0   \n",
       "7  72058700184  2011-05-01T02:15:00                       72.0   \n",
       "8  72058700184  2011-05-01T02:35:00                       72.0   \n",
       "9  72058700184  2011-05-01T03:00:00                       73.0   \n",
       "\n",
       "   HourlyDryBulbTemperature HourlyPrecipitation  HourlyRelativeHumidity  \\\n",
       "0                      75.0                <NA>                    89.0   \n",
       "1                      75.0                <NA>                    89.0   \n",
       "2                      75.0                <NA>                    89.0   \n",
       "3                      75.0                <NA>                    89.0   \n",
       "4                      75.0                <NA>                    89.0   \n",
       "5                      75.0                <NA>                    89.0   \n",
       "6                      75.0                <NA>                    89.0   \n",
       "7                      75.0                <NA>                    89.0   \n",
       "8                      75.0                <NA>                    89.0   \n",
       "9                      75.0                <NA>                    94.0   \n",
       "\n",
       "  HourlyWetBulbTemperature  HourlyWindDirection  HourlyWindSpeed  \n",
       "0                     <NA>                130.0              9.0  \n",
       "1                     <NA>                120.0              9.0  \n",
       "2                     <NA>                120.0             11.0  \n",
       "3                     <NA>                130.0             14.0  \n",
       "4                     <NA>                130.0             13.0  \n",
       "5                     <NA>                130.0             10.0  \n",
       "6                     <NA>                130.0             11.0  \n",
       "7                     <NA>                130.0             10.0  \n",
       "8                     <NA>                130.0             13.0  \n",
       "9                     <NA>                130.0              8.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output = cudf.read_parquet(\"data/parquet_out/*.parquet\")\n",
    "df_output.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent, this is more manageable for us to analyze. In this notebook, we showed how to `Extract` and `Load` with NVTabular, but not how to `Transform`. We will learn how to do so in the [next notebook](2_Transforming_with_Ops.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, please shutdown the Jupyter notebook kernel to free GPU memory. Keep an eye on that terminal to watch as everything drops back to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
